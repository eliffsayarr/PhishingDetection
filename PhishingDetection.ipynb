{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "87f27268-bfb1-467e-86c9-548a6311f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "05369971-1027-442c-afe3-ca1c972c7645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.crestonwood.com/router.php</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://shadetreetechnology.com/V4/validation/a...</td>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>5767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://support-appleld.com.secureupdate.duila...</td>\n",
       "      <td>126</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4004</td>\n",
       "      <td>5828815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://rgipt.ac.in</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>-1</td>\n",
       "      <td>107721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.iracing.com/tracks/gateway-motorspo...</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>8175</td>\n",
       "      <td>8725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  length_url  \\\n",
       "0              http://www.crestonwood.com/router.php          37   \n",
       "1  http://shadetreetechnology.com/V4/validation/a...          77   \n",
       "2  https://support-appleld.com.secureupdate.duila...         126   \n",
       "3                                 http://rgipt.ac.in          18   \n",
       "4  http://www.iracing.com/tracks/gateway-motorspo...          55   \n",
       "\n",
       "   length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  nb_or  ...  \\\n",
       "0               19   0        3           0      0      0       0      0  ...   \n",
       "1               23   1        1           0      0      0       0      0  ...   \n",
       "2               50   1        4           1      0      1       2      0  ...   \n",
       "3               11   0        2           0      0      0       0      0  ...   \n",
       "4               15   0        2           2      0      0       0      0  ...   \n",
       "\n",
       "   domain_in_title  domain_with_copyright  whois_registered_domain  \\\n",
       "0                0                      1                        0   \n",
       "1                1                      0                        0   \n",
       "2                1                      0                        0   \n",
       "3                1                      0                        0   \n",
       "4                0                      1                        0   \n",
       "\n",
       "   domain_registration_length  domain_age  web_traffic  dns_record  \\\n",
       "0                          45          -1            0           1   \n",
       "1                          77        5767            0           0   \n",
       "2                          14        4004      5828815           0   \n",
       "3                          62          -1       107721           0   \n",
       "4                         224        8175         8725           0   \n",
       "\n",
       "   google_index  page_rank      status  \n",
       "0             1          4  legitimate  \n",
       "1             1          2    phishing  \n",
       "2             1          0    phishing  \n",
       "3             0          3  legitimate  \n",
       "4             0          6  legitimate  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(\"dataset_phishing.csv\")\n",
    "# Load Dataset\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3bafd211-bcfa-44ca-be04-871f842eb63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens',\n",
       "       'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore',\n",
       "       'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma',\n",
       "       'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com',\n",
       "       'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url',\n",
       "       'ratio_digits_host', 'punycode', 'port', 'tld_in_path',\n",
       "       'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains',\n",
       "       'prefix_suffix', 'random_domain', 'shortening_service',\n",
       "       'path_extension', 'nb_redirection', 'nb_external_redirection',\n",
       "       'length_words_raw', 'char_repeat', 'shortest_words_raw',\n",
       "       'shortest_word_host', 'shortest_word_path', 'longest_words_raw',\n",
       "       'longest_word_host', 'longest_word_path', 'avg_words_raw',\n",
       "       'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand',\n",
       "       'brand_in_subdomain', 'brand_in_path', 'suspecious_tld',\n",
       "       'statistical_report', 'nb_hyperlinks', 'ratio_intHyperlinks',\n",
       "       'ratio_extHyperlinks', 'ratio_nullHyperlinks', 'nb_extCSS',\n",
       "       'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors',\n",
       "       'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags',\n",
       "       'submit_email', 'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe',\n",
       "       'popup_window', 'safe_anchor', 'onmouseover', 'right_clic',\n",
       "       'empty_title', 'domain_in_title', 'domain_with_copyright',\n",
       "       'whois_registered_domain', 'domain_registration_length', 'domain_age',\n",
       "       'web_traffic', 'dns_record', 'google_index', 'page_rank', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4c335090-a590-4ab5-8fb1-2dafd83354ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'url', 'length_url', 'length_hostname', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', \n",
    "    'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', \n",
    "    'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', \n",
    "    'https_token', 'ratio_digits_url', 'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', \n",
    "    'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', 'shortening_service', 'path_extension', \n",
    "    'char_repeat', 'shortest_words_raw', 'shortest_word_host', 'shortest_word_path', 'longest_words_raw', \n",
    "    'longest_word_host', 'longest_word_path', 'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', \n",
    "    'domain_in_brand', 'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'domain_registration_length', \n",
    "    'domain_age','status'\n",
    "]\n",
    "\n",
    "df = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5718964b-f052-4952-bf0f-8a5a1950ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: 0 (0.0%)\n",
      "length_url: 0 (0.0%)\n",
      "length_hostname: 0 (0.0%)\n",
      "nb_dots: 0 (0.0%)\n",
      "nb_hyphens: 0 (0.0%)\n",
      "nb_at: 0 (0.0%)\n",
      "nb_qm: 0 (0.0%)\n",
      "nb_and: 0 (0.0%)\n",
      "nb_or: 0 (0.0%)\n",
      "nb_eq: 0 (0.0%)\n",
      "nb_underscore: 0 (0.0%)\n",
      "nb_tilde: 0 (0.0%)\n",
      "nb_percent: 0 (0.0%)\n",
      "nb_slash: 0 (0.0%)\n",
      "nb_star: 0 (0.0%)\n",
      "nb_colon: 0 (0.0%)\n",
      "nb_comma: 0 (0.0%)\n",
      "nb_semicolumn: 0 (0.0%)\n",
      "nb_dollar: 0 (0.0%)\n",
      "nb_space: 0 (0.0%)\n",
      "nb_www: 0 (0.0%)\n",
      "nb_com: 0 (0.0%)\n",
      "nb_dslash: 0 (0.0%)\n",
      "http_in_path: 0 (0.0%)\n",
      "https_token: 0 (0.0%)\n",
      "ratio_digits_url: 0 (0.0%)\n",
      "ratio_digits_host: 0 (0.0%)\n",
      "punycode: 0 (0.0%)\n",
      "port: 0 (0.0%)\n",
      "tld_in_path: 0 (0.0%)\n",
      "tld_in_subdomain: 0 (0.0%)\n",
      "abnormal_subdomain: 0 (0.0%)\n",
      "nb_subdomains: 0 (0.0%)\n",
      "prefix_suffix: 0 (0.0%)\n",
      "random_domain: 0 (0.0%)\n",
      "shortening_service: 0 (0.0%)\n",
      "path_extension: 0 (0.0%)\n",
      "char_repeat: 0 (0.0%)\n",
      "shortest_words_raw: 0 (0.0%)\n",
      "shortest_word_host: 0 (0.0%)\n",
      "shortest_word_path: 0 (0.0%)\n",
      "longest_words_raw: 0 (0.0%)\n",
      "longest_word_host: 0 (0.0%)\n",
      "longest_word_path: 0 (0.0%)\n",
      "avg_words_raw: 0 (0.0%)\n",
      "avg_word_host: 0 (0.0%)\n",
      "avg_word_path: 0 (0.0%)\n",
      "phish_hints: 0 (0.0%)\n",
      "domain_in_brand: 0 (0.0%)\n",
      "brand_in_subdomain: 0 (0.0%)\n",
      "brand_in_path: 0 (0.0%)\n",
      "suspecious_tld: 0 (0.0%)\n",
      "domain_registration_length: 0 (0.0%)\n",
      "domain_age: 0 (0.0%)\n",
      "status: 0 (0.0%)\n",
      "\n",
      "Total missing values: 0 (0.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null = df.isnull().sum()\n",
    "for i in range(len(df.columns)):\n",
    "    print(f\"{df.columns[i]}: {null[i]} ({(null[i]/len(df))*100}%)\")\n",
    "total_cells = np.prod(df.shape)\n",
    "total_missing = null.sum()\n",
    "print(f\"\\nTotal missing values: {total_missing} ({(total_missing/total_cells) * 100}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "649b7135-306b-4c4e-981d-e55cf0951d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with values less than zero:\n",
      "Column: domain_registration_length\n",
      "       domain_registration_length\n",
      "443                            -1\n",
      "776                            -1\n",
      "870                            -1\n",
      "1092                           -1\n",
      "1208                           -1\n",
      "1225                           -1\n",
      "1298                           -1\n",
      "1830                           -1\n",
      "2231                           -1\n",
      "2316                           -1\n",
      "2440                           -1\n",
      "2629                           -1\n",
      "2662                           -1\n",
      "2784                           -1\n",
      "2805                           -1\n",
      "3819                           -1\n",
      "3894                           -1\n",
      "3908                           -1\n",
      "4307                           -1\n",
      "4451                           -1\n",
      "4705                           -1\n",
      "5195                           -1\n",
      "5520                           -1\n",
      "5977                           -1\n",
      "6130                           -1\n",
      "6623                           -1\n",
      "6673                           -1\n",
      "7116                           -1\n",
      "7204                           -1\n",
      "7896                           -1\n",
      "8225                           -1\n",
      "8512                           -1\n",
      "8545                           -1\n",
      "9328                           -1\n",
      "9415                           -1\n",
      "9939                           -1\n",
      "10000                          -1\n",
      "10209                          -1\n",
      "10474                          -1\n",
      "10549                          -1\n",
      "10693                          -1\n",
      "10834                          -1\n",
      "11023                          -1\n",
      "11027                          -1\n",
      "11331                          -1\n",
      "11373                          -1\n",
      "Column: domain_age\n",
      "       domain_age\n",
      "0              -1\n",
      "3              -1\n",
      "5              -1\n",
      "10             -1\n",
      "29             -1\n",
      "...           ...\n",
      "11393          -1\n",
      "11404          -1\n",
      "11408          -1\n",
      "11414          -1\n",
      "11429          -1\n",
      "\n",
      "[1837 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "negative_values = (df[numeric_cols] < 0).any()\n",
    "columns_with_negatives = negative_values[negative_values].index.tolist()\n",
    "if columns_with_negatives:\n",
    "    print(\"Columns with values less than zero:\")\n",
    "    for col in columns_with_negatives:\n",
    "        print(f\"Column: {col}\")\n",
    "        print(df[df[col] < 0][[col]])\n",
    "else:\n",
    "    print(\"There's no columns with value less than zero.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7ca93001-4123-4453-bf84-994ea773aea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "11425    0\n",
       "11426    0\n",
       "11427    0\n",
       "11428    0\n",
       "11429    0\n",
       "Name: nb_or, Length: 11430, dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"nb_or\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3c2b5bde-3ffd-4b2f-bfc9-8d9e8b880acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [url, length_url, length_hostname, nb_dots, nb_hyphens, nb_at, nb_qm, nb_and, nb_or, nb_eq, nb_underscore, nb_tilde, nb_percent, nb_slash, nb_star, nb_colon, nb_comma, nb_semicolumn, nb_dollar, nb_space, nb_www, nb_com, nb_dslash, http_in_path, https_token, ratio_digits_url, ratio_digits_host, punycode, port, tld_in_path, tld_in_subdomain, abnormal_subdomain, nb_subdomains, prefix_suffix, random_domain, shortening_service, path_extension, char_repeat, shortest_words_raw, shortest_word_host, shortest_word_path, longest_words_raw, longest_word_host, longest_word_path, avg_words_raw, avg_word_host, avg_word_path, phish_hints, domain_in_brand, brand_in_subdomain, brand_in_path, suspecious_tld, domain_registration_length, domain_age, status]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "non_zero_values = df[df[\"nb_or\"] != 0]\n",
    "print(non_zero_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7ec00754-4d80-4f5d-af4e-9f7ad1a9b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['nb_or'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "cae03e74-954e-4370-a46d-2f7560cbbb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'length_url', 'length_hostname', 'nb_dots', 'nb_hyphens',\n",
       "       'nb_at', 'nb_qm', 'nb_and', 'nb_eq', 'nb_underscore', 'nb_tilde',\n",
       "       'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma',\n",
       "       'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com',\n",
       "       'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url',\n",
       "       'ratio_digits_host', 'punycode', 'port', 'tld_in_path',\n",
       "       'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains',\n",
       "       'prefix_suffix', 'random_domain', 'shortening_service',\n",
       "       'path_extension', 'char_repeat', 'shortest_words_raw',\n",
       "       'shortest_word_host', 'shortest_word_path', 'longest_words_raw',\n",
       "       'longest_word_host', 'longest_word_path', 'avg_words_raw',\n",
       "       'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand',\n",
       "       'brand_in_subdomain', 'brand_in_path', 'suspecious_tld',\n",
       "       'domain_registration_length', 'domain_age', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d991395a-e6e1-4b9b-895c-1c5fd3b65224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "data['status'].value_counts(normalize=True).plot(\n",
    "    kind='pie',\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['blue', 'orange'],\n",
    "    explode=[0.1, 0]\n",
    "    )\n",
    "plt.title('Distribution (Phishing vs Legimite)')\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cb404324-dc55-4c53-8637-db2e5694f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "                                                 url  length_url  \\\n",
      "0              http://www.crestonwood.com/router.php          37   \n",
      "1  http://shadetreetechnology.com/V4/validation/a...          77   \n",
      "2  https://support-appleld.com.secureupdate.duila...         126   \n",
      "3                                 http://rgipt.ac.in          18   \n",
      "4  http://www.iracing.com/tracks/gateway-motorspo...          55   \n",
      "\n",
      "   length_hostname  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  nb_eq  \\\n",
      "0               19        3           0      0      0       0      0   \n",
      "1               23        1           0      0      0       0      0   \n",
      "2               50        4           1      0      1       2      3   \n",
      "3               11        2           0      0      0       0      0   \n",
      "4               15        2           2      0      0       0      0   \n",
      "\n",
      "   nb_underscore  ...  avg_words_raw  avg_word_host  avg_word_path  \\\n",
      "0              0  ...       5.750000            7.0       4.500000   \n",
      "1              0  ...      15.750000           19.0      14.666667   \n",
      "2              2  ...       8.250000            8.4       8.142857   \n",
      "3              0  ...       5.000000            5.0       0.000000   \n",
      "4              0  ...       6.333333            5.0       7.000000   \n",
      "\n",
      "   phish_hints  domain_in_brand  brand_in_subdomain  brand_in_path  \\\n",
      "0            0                0                   0              0   \n",
      "1            0                0                   0              0   \n",
      "2            0                0                   0              0   \n",
      "3            0                0                   0              0   \n",
      "4            0                0                   0              0   \n",
      "\n",
      "   suspecious_tld  domain_registration_length  domain_age  \n",
      "0               0                          45          -1  \n",
      "1               0                          77        5767  \n",
      "2               0                          14        4004  \n",
      "3               0                          62          -1  \n",
      "4               0                         224        8175  \n",
      "\n",
      "[5 rows x 53 columns]\n",
      "\n",
      "Target (y):\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: status, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "11425    0\n",
       "11426    1\n",
       "11427    0\n",
       "11428    0\n",
       "11429    1\n",
       "Name: status, Length: 11430, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ã–zellikler (features) ve hedef (target) olarak ayÄ±rma\n",
    "df['status'] = df['status'].map({'phishing': 1, 'legitimate': 0})\n",
    "\n",
    "X = df.drop(columns=['status'])  \n",
    "y = df['status']  \n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n",
    "\n",
    "df['status']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c9d27-4a4d-4500-8b30-7de939f7d418",
   "metadata": {},
   "source": [
    "# Process text features (TD-IDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e4dafa24-729b-4701-a990-149fd7b280d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_numeric_columns = df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "print(non_numeric_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f693537a-8eb2-4551-be7a-08b2bdc2db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benzersiz terim sayÄ±sÄ±: 11431\n"
     ]
    }
   ],
   "source": [
    "unique_terms = len(set(\" \".join(df['url']).split()))\n",
    "print(f\"Benzersiz terim sayÄ±sÄ±: {unique_terms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c97d96f2-4ae4-4a17-8cd9-3fec493ba45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En alakalÄ± meÅŸru URL terimleri (TF-IDF):\n",
      "https www    0.163982\n",
      "org          0.047030\n",
      "html         0.035618\n",
      "pdf          0.021513\n",
      "en           0.020914\n",
      "wiki         0.018901\n",
      "de           0.016641\n",
      "net          0.016623\n",
      "blogspot     0.016225\n",
      "ru           0.016223\n",
      "dtype: float64\n",
      "\n",
      "En alakalÄ± phishing URL terimleri (TF-IDF):\n",
      "php             0.049426\n",
      "html            0.032115\n",
      "blogspot        0.030934\n",
      "blogspot com    0.030177\n",
      "wp              0.026740\n",
      "net             0.025899\n",
      "login           0.023520\n",
      "index           0.020900\n",
      "amp             0.019654\n",
      "https www       0.015817\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "urls = pd.DataFrame({'url': df['url'], 'label': df['status']})\n",
    "\n",
    "# TF-IDF VektÃ¶rizasyonu\n",
    "tfidf_vect = TfidfVectorizer(\n",
    "    #analyzer='char_wb',  # URL'ler iÃ§in karakter tabanlÄ± analiz\n",
    "    ngram_range=(1, 2),\n",
    "    max_df=0.25,\n",
    "    max_features=1000,\n",
    "    stop_words=None\n",
    ")\n",
    "\n",
    "urls_tfidfs = tfidf_vect.fit_transform(urls['url'])\n",
    "\n",
    "# TF-IDF skorlarÄ±nÄ± DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "tfidfs = pd.DataFrame.sparse.from_spmatrix(\n",
    "    urls_tfidfs, \n",
    "    columns=tfidf_vect.get_feature_names_out()\n",
    ")\n",
    "tfidfs['label'] = urls['label']\n",
    "\n",
    "# MeÅŸru URL'lerdeki en alakalÄ± terimleri bul\n",
    "legitimate_terms = tfidfs[tfidfs['label'] == 0].drop('label', axis=1).mean(axis=0).sort_values(ascending=False)[:10]\n",
    "\n",
    "# Phishing URL'lerindeki en alakalÄ± terimleri bul\n",
    "phishing_terms = tfidfs[tfidfs['label'] == 1].drop('label', axis=1).mean(axis=0).sort_values(ascending=False)[:10]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# MeÅŸru URLs\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(legitimate_terms.index, legitimate_terms.values, color='green')\n",
    "plt.title('En AlakalÄ± MeÅŸru URL Terimleri (TF-IDF)')\n",
    "plt.xlabel('TF-IDF Skoru')\n",
    "\n",
    "# Phishing URLs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(phishing_terms.index, phishing_terms.values, color='red')\n",
    "plt.title('En AlakalÄ± Phishing URL Terimleri (TF-IDF)')\n",
    "plt.xlabel('TF-IDF Skoru')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    #analyzer='char_wb',\n",
    "    ngram_range=(1, 2),\n",
    "    max_df=0.25,\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "urls_tf = cv.fit_transform(urls['url'])\n",
    "tfs = pd.DataFrame.sparse.from_spmatrix(urls_tf, columns=cv.get_feature_names_out())\n",
    "tfs['label'] = urls['label']\n",
    "\n",
    "# En sÄ±k kullanÄ±lan terimleri bul\n",
    "legitimate_freq = tfs[tfs['label'] == 0].drop('label', axis=1).sum(axis=0).nlargest(10)\n",
    "phishing_freq = tfs[tfs['label'] == 1].drop('label', axis=1).sum(axis=0).nlargest(10)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(legitimate_freq.index, legitimate_freq.values, color='green')\n",
    "plt.title('En SÄ±k KullanÄ±lan MeÅŸru URL Terimleri')\n",
    "plt.xlabel('Frekans')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(phishing_freq.index, phishing_freq.values, color='red')\n",
    "plt.title('En SÄ±k KullanÄ±lan Phishing URL Terimleri')\n",
    "plt.xlabel('Frekans')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEn alakalÄ± meÅŸru URL terimleri (TF-IDF):\")\n",
    "print(legitimate_terms)\n",
    "print(\"\\nEn alakalÄ± phishing URL terimleri (TF-IDF):\")\n",
    "print(phishing_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d91614bf-3577-48f3-9089-73e1a2db7419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target (y):\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "urls = df['url']\n",
    "df = df.drop('url', axis=1)\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d33e2f1c-38c1-4e63-85c1-d8ce8f38e031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame'in yeni boyutu: (11430, 1054)\n",
      "\n",
      "Yeni sÃ¼tunlardan ilk 5 tanesi:\n",
      "['yourdictionary com', 'youtube', 'youtube com', 'za', 'status']\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, tfidfs], axis=1)\n",
    "\n",
    "print(\"DataFrame'in yeni boyutu:\", df.shape)\n",
    "print(\"\\nYeni sÃ¼tunlardan ilk 5 tanesi:\")\n",
    "print(list(df.columns)[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ebe5f2d5-ccc3-470a-896c-726fd1cd0464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>nb_underscore</th>\n",
       "      <th>nb_tilde</th>\n",
       "      <th>...</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourdictionary</th>\n",
       "      <th>yourdictionary com</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube com</th>\n",
       "      <th>za</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1054 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length_url  length_hostname  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  \\\n",
       "0          37               19        3           0      0      0       0   \n",
       "1          77               23        1           0      0      0       0   \n",
       "2         126               50        4           1      0      1       2   \n",
       "3          18               11        2           0      0      0       0   \n",
       "4          55               15        2           2      0      0       0   \n",
       "\n",
       "   nb_eq  nb_underscore  nb_tilde  ...  xyz  yahoo  you  your  yourdictionary  \\\n",
       "0      0              0         0  ...  0.0    0.0  0.0   0.0             0.0   \n",
       "1      0              0         0  ...  0.0    0.0  0.0   0.0             0.0   \n",
       "2      3              2         0  ...  0.0    0.0  0.0   0.0             0.0   \n",
       "3      0              0         0  ...  0.0    0.0  0.0   0.0             0.0   \n",
       "4      0              0         0  ...  0.0    0.0  0.0   0.0             0.0   \n",
       "\n",
       "   yourdictionary com  youtube  youtube com   za  status  \n",
       "0                 0.0      0.0          0.0  0.0       0  \n",
       "1                 0.0      0.0          0.0  0.0       1  \n",
       "2                 0.0      0.0          0.0  0.0       1  \n",
       "3                 0.0      0.0          0.0  0.0       0  \n",
       "4                 0.0      0.0          0.0  0.0       0  \n",
       "\n",
       "[5 rows x 1054 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d8856dee-e4ff-46bc-81c1-42fbc41e284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>nb_underscore</th>\n",
       "      <th>nb_tilde</th>\n",
       "      <th>...</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourdictionary</th>\n",
       "      <th>yourdictionary com</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube com</th>\n",
       "      <th>za</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015347</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039902</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069982</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026397</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1054 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length_url  length_hostname   nb_dots  nb_hyphens  nb_at     nb_qm  \\\n",
       "0    0.015347         0.071429  0.086957    0.000000    0.0  0.000000   \n",
       "1    0.039902         0.090476  0.000000    0.000000    0.0  0.000000   \n",
       "2    0.069982         0.219048  0.130435    0.023256    0.0  0.333333   \n",
       "3    0.003683         0.033333  0.043478    0.000000    0.0  0.000000   \n",
       "4    0.026397         0.052381  0.043478    0.046512    0.0  0.000000   \n",
       "\n",
       "     nb_and     nb_eq  nb_underscore  nb_tilde  ...  xyz  yahoo  you  your  \\\n",
       "0  0.000000  0.000000       0.000000       0.0  ...  0.0    0.0  0.0   0.0   \n",
       "1  0.000000  0.000000       0.000000       0.0  ...  0.0    0.0  0.0   0.0   \n",
       "2  0.105263  0.157895       0.111111       0.0  ...  0.0    0.0  0.0   0.0   \n",
       "3  0.000000  0.000000       0.000000       0.0  ...  0.0    0.0  0.0   0.0   \n",
       "4  0.000000  0.000000       0.000000       0.0  ...  0.0    0.0  0.0   0.0   \n",
       "\n",
       "   yourdictionary  yourdictionary com  youtube  youtube com   za  status  \n",
       "0             0.0                 0.0      0.0          0.0  0.0       0  \n",
       "1             0.0                 0.0      0.0          0.0  0.0       1  \n",
       "2             0.0                 0.0      0.0          0.0  0.0       1  \n",
       "3             0.0                 0.0      0.0          0.0  0.0       0  \n",
       "4             0.0                 0.0      0.0          0.0  0.0       0  \n",
       "\n",
       "[5 rows x 1054 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize numeric features\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_features = numeric_features.drop('status') if 'status' in numeric_features else numeric_features\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5fe5e8b6-b6c7-481b-be74-8bedf953af3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_eq</th>\n",
       "      <th>nb_underscore</th>\n",
       "      <th>nb_tilde</th>\n",
       "      <th>...</th>\n",
       "      <th>xyz</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourdictionary</th>\n",
       "      <th>yourdictionary com</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube com</th>\n",
       "      <th>za</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.081382</td>\n",
       "      <td>0.064381</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.047069</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033946</td>\n",
       "      <td>0.051320</td>\n",
       "      <td>0.059552</td>\n",
       "      <td>0.048537</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>0.121485</td>\n",
       "      <td>0.043228</td>\n",
       "      <td>0.052543</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>0.081274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032373</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.033489</td>\n",
       "      <td>0.033489</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.500022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.021486</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.036219</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1054 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         length_url  length_hostname       nb_dots    nb_hyphens  \\\n",
       "count  11430.000000     11430.000000  11430.000000  11430.000000   \n",
       "mean       0.030158         0.081382      0.064381      0.023199   \n",
       "std        0.033946         0.051320      0.059552      0.048537   \n",
       "min        0.000000         0.000000      0.000000      0.000000   \n",
       "25%        0.012891         0.052381      0.043478      0.000000   \n",
       "50%        0.021486         0.071429      0.043478      0.000000   \n",
       "75%        0.036219         0.095238      0.086957      0.023256   \n",
       "max        1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "              nb_at         nb_qm        nb_and         nb_eq  nb_underscore  \\\n",
       "count  11430.000000  11430.000000  11430.000000  11430.000000   11430.000000   \n",
       "mean       0.005556      0.047069      0.008542      0.015430       0.017926   \n",
       "std        0.038875      0.121485      0.043228      0.052543       0.060741   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000       1.000000   \n",
       "\n",
       "           nb_tilde  ...           xyz         yahoo           you  \\\n",
       "count  11430.000000  ...  11430.000000  11430.000000  11430.000000   \n",
       "mean       0.006649  ...      0.001185      0.001363      0.000643   \n",
       "std        0.081274  ...      0.032373      0.029431      0.018658   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "max        1.000000  ...      1.000000      1.000000      1.000000   \n",
       "\n",
       "               your  yourdictionary  yourdictionary com       youtube  \\\n",
       "count  11430.000000    11430.000000        11430.000000  11430.000000   \n",
       "mean       0.001309        0.001495            0.001495      0.002854   \n",
       "std        0.027556        0.033489            0.033489      0.046742   \n",
       "min        0.000000        0.000000            0.000000      0.000000   \n",
       "25%        0.000000        0.000000            0.000000      0.000000   \n",
       "50%        0.000000        0.000000            0.000000      0.000000   \n",
       "75%        0.000000        0.000000            0.000000      0.000000   \n",
       "max        1.000000        1.000000            1.000000      1.000000   \n",
       "\n",
       "        youtube com            za        status  \n",
       "count  11430.000000  11430.000000  11430.000000  \n",
       "mean       0.002849      0.001524      0.500000  \n",
       "std        0.047160      0.030829      0.500022  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.500000  \n",
       "75%        0.000000      0.000000      1.000000  \n",
       "max        1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 1054 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69df5c-08e9-435d-83d1-abcab713f2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82547255-3b99-432b-b313-20b58288e899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b0649-496a-42ab-ab6e-e40bde3a36cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb5eb9-6b62-482f-a538-a2de0eeb33af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "04398cc3-6232-493f-b2e9-9c5f8eddb9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "   length_url  length_hostname   nb_dots  nb_hyphens  nb_at     nb_qm  \\\n",
      "0    0.015347         0.071429  0.086957    0.000000    0.0  0.000000   \n",
      "1    0.039902         0.090476  0.000000    0.000000    0.0  0.000000   \n",
      "2    0.069982         0.219048  0.130435    0.023256    0.0  0.333333   \n",
      "3    0.003683         0.033333  0.043478    0.000000    0.0  0.000000   \n",
      "4    0.026397         0.052381  0.043478    0.046512    0.0  0.000000   \n",
      "\n",
      "     nb_and     nb_eq  nb_underscore  nb_tilde  ...  www youtube  xyz  yahoo  \\\n",
      "0  0.000000  0.000000       0.000000       0.0  ...          0.0  0.0    0.0   \n",
      "1  0.000000  0.000000       0.000000       0.0  ...          0.0  0.0    0.0   \n",
      "2  0.105263  0.157895       0.111111       0.0  ...          0.0  0.0    0.0   \n",
      "3  0.000000  0.000000       0.000000       0.0  ...          0.0  0.0    0.0   \n",
      "4  0.000000  0.000000       0.000000       0.0  ...          0.0  0.0    0.0   \n",
      "\n",
      "   you  your  yourdictionary  yourdictionary com  youtube  youtube com   za  \n",
      "0  0.0   0.0             0.0                 0.0      0.0          0.0  0.0  \n",
      "1  0.0   0.0             0.0                 0.0      0.0          0.0  0.0  \n",
      "2  0.0   0.0             0.0                 0.0      0.0          0.0  0.0  \n",
      "3  0.0   0.0             0.0                 0.0      0.0          0.0  0.0  \n",
      "4  0.0   0.0             0.0                 0.0      0.0          0.0  0.0  \n",
      "\n",
      "[5 rows x 1052 columns]\n",
      "\n",
      "Target (y):\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ã–zellikler (features) ve hedef (target) olarak ayÄ±rma\n",
    "#df['status'] = df['status'].map({'phishing': 1, 'legitimate': 0})\n",
    "\n",
    "X = df.drop(columns=['status'])  \n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b020e57-06bf-496b-85a0-101e6cc446cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluation Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "86329439-6b1c-4443-a2da-af51249c98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_graph(results):\n",
    "\n",
    "    acc = results.history['accuracy']\n",
    "    val_acc = results.history['val_accuracy']\n",
    "    epochs = range(len(acc))\n",
    "    fig = plt.figure(figsize=(14,7))\n",
    "    plt.plot(epochs,acc,'r',label=\"Training Accuracy\")\n",
    "    plt.plot(epochs,val_acc,'b',label=\"Validation Accuracy\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"ACCURACY GRAPH\")\n",
    "    plt.show()\n",
    "    \n",
    "    loss = results.history['loss']\n",
    "    val_loss = results.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    fig = plt.figure(figsize=(14,7))\n",
    "    plt.plot(epochs,loss,'r',label=\"Training loss\")\n",
    "    plt.plot(epochs,val_loss,'b',label=\"Validation loss\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"LOSS GRAPH\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669bd7f1-1113-4d54-b2ab-15669bbd6f92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CNN MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5345070a-615f-4704-9028-dd35776327d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "70efe9a1-e1c7-4f3b-953e-e0b587be52e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9144, 2052, 1) (9144,)\n",
      "(2286, 2052, 1) (2286,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "998cd787-b363-4519-9656-c2259eb74898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2052, 1)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = X_train[1].shape\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b7999-4c37-41e4-80e9-528d638aa0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6ef63060-5e99-42af-9bec-c048b7df7f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 2052, 16)          64        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 2052, 16)          0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 2052, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 1026, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 1026, 32)          1568      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1026, 32)          0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 1026, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 513, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 513, 64)           6208      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 513, 64)           0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 513, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 257, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 257, 128)          24704     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 257, 128)          0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 257, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 129, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 129, 256)          98560     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 129, 256)          0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 129, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 65, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16640)             0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16640)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               8520192   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8653793 (33.01 MB)\n",
      "Trainable params: 8652801 (33.01 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from keras import Sequential\n",
    "\n",
    "def CNN(input_size):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(input_size))\n",
    "    model.add(layers.Conv1D(filters = 16,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 128,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 256,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(512,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "CNN_model = CNN(input_size)\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f181c393-6044-48af-978b-b1c577854b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7288\n",
      "Epoch 1: val_loss improved from inf to 0.75235, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 23s 367ms/step - loss: 0.6789 - accuracy: 0.7288 - val_loss: 0.7523 - val_accuracy: 0.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.8068\n",
      "Epoch 2: val_loss did not improve from 0.75235\n",
      "58/58 [==============================] - 20s 342ms/step - loss: 0.3969 - accuracy: 0.8068 - val_loss: 0.8262 - val_accuracy: 0.5167\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8377\n",
      "Epoch 3: val_loss did not improve from 0.75235\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.3496 - accuracy: 0.8377 - val_loss: 0.7999 - val_accuracy: 0.5167\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.8529\n",
      "Epoch 4: val_loss improved from 0.75235 to 0.65439, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.3236 - accuracy: 0.8529 - val_loss: 0.6544 - val_accuracy: 0.5549\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.8734\n",
      "Epoch 5: val_loss improved from 0.65439 to 0.60077, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 21s 355ms/step - loss: 0.2935 - accuracy: 0.8734 - val_loss: 0.6008 - val_accuracy: 0.5998\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.8731\n",
      "Epoch 6: val_loss improved from 0.60077 to 0.42343, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 21s 366ms/step - loss: 0.2840 - accuracy: 0.8731 - val_loss: 0.4234 - val_accuracy: 0.8125\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.8824\n",
      "Epoch 7: val_loss did not improve from 0.42343\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.2641 - accuracy: 0.8824 - val_loss: 0.5642 - val_accuracy: 0.7682\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.8912\n",
      "Epoch 8: val_loss improved from 0.42343 to 0.33038, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 20s 345ms/step - loss: 0.2481 - accuracy: 0.8912 - val_loss: 0.3304 - val_accuracy: 0.8442\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.8983\n",
      "Epoch 9: val_loss improved from 0.33038 to 0.31098, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 23s 397ms/step - loss: 0.2326 - accuracy: 0.8983 - val_loss: 0.3110 - val_accuracy: 0.8600\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9061\n",
      "Epoch 10: val_loss improved from 0.31098 to 0.27205, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2228 - accuracy: 0.9061 - val_loss: 0.2720 - val_accuracy: 0.8841\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.9088\n",
      "Epoch 11: val_loss did not improve from 0.27205\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2137 - accuracy: 0.9088 - val_loss: 0.3683 - val_accuracy: 0.8726\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9081\n",
      "Epoch 12: val_loss improved from 0.27205 to 0.23697, saving model to CNN_MODEL.h5\n",
      "58/58 [==============================] - 23s 401ms/step - loss: 0.2118 - accuracy: 0.9081 - val_loss: 0.2370 - val_accuracy: 0.8972\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9100\n",
      "Epoch 13: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.2118 - accuracy: 0.9100 - val_loss: 0.2416 - val_accuracy: 0.9005\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9188\n",
      "Epoch 14: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 23s 392ms/step - loss: 0.1913 - accuracy: 0.9188 - val_loss: 0.2767 - val_accuracy: 0.8896\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9237\n",
      "Epoch 15: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.1823 - accuracy: 0.9237 - val_loss: 0.2618 - val_accuracy: 0.9021\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9265\n",
      "Epoch 16: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.1768 - accuracy: 0.9265 - val_loss: 0.2562 - val_accuracy: 0.9092\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9280\n",
      "Epoch 17: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 441ms/step - loss: 0.1733 - accuracy: 0.9280 - val_loss: 0.4293 - val_accuracy: 0.8759\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.9289\n",
      "Epoch 18: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 441ms/step - loss: 0.1636 - accuracy: 0.9289 - val_loss: 0.2618 - val_accuracy: 0.9027\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9297\n",
      "Epoch 19: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 453ms/step - loss: 0.1627 - accuracy: 0.9297 - val_loss: 0.2808 - val_accuracy: 0.9021\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9368\n",
      "Epoch 20: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 452ms/step - loss: 0.1557 - accuracy: 0.9368 - val_loss: 0.2865 - val_accuracy: 0.9098\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9277\n",
      "Epoch 21: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 456ms/step - loss: 0.1612 - accuracy: 0.9277 - val_loss: 0.2643 - val_accuracy: 0.9021\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9341\n",
      "Epoch 22: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 451ms/step - loss: 0.1570 - accuracy: 0.9341 - val_loss: 0.2503 - val_accuracy: 0.9049\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9382\n",
      "Epoch 23: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 450ms/step - loss: 0.1459 - accuracy: 0.9382 - val_loss: 0.3169 - val_accuracy: 0.9038\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9364\n",
      "Epoch 24: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 442ms/step - loss: 0.1506 - accuracy: 0.9364 - val_loss: 0.2801 - val_accuracy: 0.9038\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9403\n",
      "Epoch 25: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 442ms/step - loss: 0.1413 - accuracy: 0.9403 - val_loss: 0.3098 - val_accuracy: 0.9076\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9414\n",
      "Epoch 26: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 443ms/step - loss: 0.1334 - accuracy: 0.9414 - val_loss: 0.3266 - val_accuracy: 0.9109\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9407\n",
      "Epoch 27: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.1362 - accuracy: 0.9407 - val_loss: 0.2725 - val_accuracy: 0.9153\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9419\n",
      "Epoch 28: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.1316 - accuracy: 0.9419 - val_loss: 0.2866 - val_accuracy: 0.9081\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9431\n",
      "Epoch 29: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 27s 462ms/step - loss: 0.1332 - accuracy: 0.9431 - val_loss: 0.4480 - val_accuracy: 0.8939\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9441\n",
      "Epoch 30: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 27s 461ms/step - loss: 0.1298 - accuracy: 0.9441 - val_loss: 0.2923 - val_accuracy: 0.9081\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9423\n",
      "Epoch 31: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 27s 462ms/step - loss: 0.1303 - accuracy: 0.9423 - val_loss: 0.3216 - val_accuracy: 0.9087\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9481\n",
      "Epoch 32: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 455ms/step - loss: 0.1188 - accuracy: 0.9481 - val_loss: 0.3012 - val_accuracy: 0.9120\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9452\n",
      "Epoch 33: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 27s 463ms/step - loss: 0.1246 - accuracy: 0.9452 - val_loss: 0.3780 - val_accuracy: 0.9016\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9482\n",
      "Epoch 34: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 448ms/step - loss: 0.1229 - accuracy: 0.9482 - val_loss: 0.3291 - val_accuracy: 0.9098\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9486\n",
      "Epoch 35: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 447ms/step - loss: 0.1197 - accuracy: 0.9486 - val_loss: 0.3026 - val_accuracy: 0.9005\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9464\n",
      "Epoch 36: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 26s 450ms/step - loss: 0.1229 - accuracy: 0.9464 - val_loss: 0.5391 - val_accuracy: 0.8934\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9472\n",
      "Epoch 37: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.1193 - accuracy: 0.9472 - val_loss: 0.2937 - val_accuracy: 0.9158\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9508\n",
      "Epoch 38: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.1140 - accuracy: 0.9508 - val_loss: 0.3462 - val_accuracy: 0.9125\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9482\n",
      "Epoch 39: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.1203 - accuracy: 0.9482 - val_loss: 0.2980 - val_accuracy: 0.9103\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9489\n",
      "Epoch 40: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 24s 419ms/step - loss: 0.1150 - accuracy: 0.9489 - val_loss: 0.2955 - val_accuracy: 0.9158\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9520\n",
      "Epoch 41: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.1132 - accuracy: 0.9520 - val_loss: 0.6976 - val_accuracy: 0.8803\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9465\n",
      "Epoch 42: val_loss did not improve from 0.23697\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.1197 - accuracy: 0.9465 - val_loss: 0.3116 - val_accuracy: 0.9087\n",
      "Epoch 42: early stopping\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "CNN_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint('CNN_MODEL.h5',verbose=1,save_best_only=True),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001,patience=30,verbose=1)]\n",
    "CNN_results_ = CNN_model.fit(X_train,y_train,validation_split=0.2,batch_size=128,epochs=200,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bdc6d4b7-c1d0-4270-abef-43c1460dfbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 21ms/step - loss: 0.2700 - accuracy: 0.9151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26997464895248413, 0.9151356220245361]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.evaluate(X_test,y_test,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bc62f-53b6-418b-8cc3-88835f56e9ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5ab03771-c0ac-4cc4-9366-828bc12156cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2286, 1052, 1)\n",
      "(9144, 1052, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) \n",
    "print(X_test.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3fb6e688-f797-4694-a108-896809f9b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.5664\n",
      "Epoch 1: val_loss improved from inf to 0.70229, saving model to Optimized_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 258s 4s/step - loss: 0.6672 - accuracy: 0.5664 - val_loss: 0.7023 - val_accuracy: 0.4833\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.5791\n",
      "Epoch 2: val_loss did not improve from 0.70229\n",
      "58/58 [==============================] - 249s 4s/step - loss: 0.6379 - accuracy: 0.5791 - val_loss: 0.7440 - val_accuracy: 0.4833\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.5880\n",
      "Epoch 3: val_loss did not improve from 0.70229\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.6207 - accuracy: 0.5880 - val_loss: 0.7488 - val_accuracy: 0.4833\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.6004\n",
      "Epoch 4: val_loss improved from 0.70229 to 0.69351, saving model to Optimized_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.6115 - accuracy: 0.6004 - val_loss: 0.6935 - val_accuracy: 0.5167\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.5930\n",
      "Epoch 5: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.6168 - accuracy: 0.5930 - val_loss: 1.2644 - val_accuracy: 0.4828\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6032 - accuracy: 0.6135\n",
      "Epoch 6: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 239s 4s/step - loss: 0.6032 - accuracy: 0.6135 - val_loss: 1.6318 - val_accuracy: 0.4702\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5885 - accuracy: 0.6309\n",
      "Epoch 7: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 274s 5s/step - loss: 0.5885 - accuracy: 0.6309 - val_loss: 1.8843 - val_accuracy: 0.4790\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.6137\n",
      "Epoch 8: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 275s 5s/step - loss: 0.5943 - accuracy: 0.6137 - val_loss: 0.9115 - val_accuracy: 0.4915\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.5873\n",
      "Epoch 9: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 247s 4s/step - loss: 0.5994 - accuracy: 0.5873 - val_loss: 2.0189 - val_accuracy: 0.4992\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.6227\n",
      "Epoch 10: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 254s 4s/step - loss: 0.5827 - accuracy: 0.6227 - val_loss: 2.8508 - val_accuracy: 0.5079\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5571 - accuracy: 0.6559\n",
      "Epoch 11: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 260s 4s/step - loss: 0.5571 - accuracy: 0.6559 - val_loss: 2.6798 - val_accuracy: 0.4795\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.6718\n",
      "Epoch 12: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 251s 4s/step - loss: 0.5490 - accuracy: 0.6718 - val_loss: 3.4558 - val_accuracy: 0.4882\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.6770\n",
      "Epoch 13: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 254s 4s/step - loss: 0.5439 - accuracy: 0.6770 - val_loss: 1.6557 - val_accuracy: 0.5003\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.6782\n",
      "Epoch 14: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 255s 4s/step - loss: 0.5489 - accuracy: 0.6782 - val_loss: 3.8391 - val_accuracy: 0.4817\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.6998\n",
      "Epoch 15: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 263s 5s/step - loss: 0.5394 - accuracy: 0.6998 - val_loss: 4.8114 - val_accuracy: 0.4833\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7312\n",
      "Epoch 16: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 260s 4s/step - loss: 0.5134 - accuracy: 0.7312 - val_loss: 3.1923 - val_accuracy: 0.4833\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.6682\n",
      "Epoch 17: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 262s 5s/step - loss: 0.5573 - accuracy: 0.6682 - val_loss: 1.0964 - val_accuracy: 0.4374\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.7214\n",
      "Epoch 18: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 236s 4s/step - loss: 0.5239 - accuracy: 0.7214 - val_loss: 3.5924 - val_accuracy: 0.5183\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.7225\n",
      "Epoch 19: val_loss did not improve from 0.69351\n",
      "58/58 [==============================] - 236s 4s/step - loss: 0.5240 - accuracy: 0.7225 - val_loss: 0.8440 - val_accuracy: 0.5528\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.7509\n",
      "Epoch 20: val_loss improved from 0.69351 to 0.68272, saving model to Optimized_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.4838 - accuracy: 0.7509 - val_loss: 0.6827 - val_accuracy: 0.5949\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7937\n",
      "Epoch 21: val_loss improved from 0.68272 to 0.58715, saving model to Optimized_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 239s 4s/step - loss: 0.4399 - accuracy: 0.7937 - val_loss: 0.5872 - val_accuracy: 0.6463\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8066\n",
      "Epoch 22: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 233s 4s/step - loss: 0.4338 - accuracy: 0.8066 - val_loss: 0.6924 - val_accuracy: 0.5566\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8384\n",
      "Epoch 23: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 235s 4s/step - loss: 0.3736 - accuracy: 0.8384 - val_loss: 1.0783 - val_accuracy: 0.5156\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8087\n",
      "Epoch 24: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 237s 4s/step - loss: 0.4298 - accuracy: 0.8087 - val_loss: 0.7230 - val_accuracy: 0.5440\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8331\n",
      "Epoch 25: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 226s 4s/step - loss: 0.3761 - accuracy: 0.8331 - val_loss: 1.0269 - val_accuracy: 0.5703\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8455\n",
      "Epoch 26: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 242s 4s/step - loss: 0.3569 - accuracy: 0.8455 - val_loss: 0.6240 - val_accuracy: 0.6796\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8653\n",
      "Epoch 27: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 247s 4s/step - loss: 0.3198 - accuracy: 0.8653 - val_loss: 0.6405 - val_accuracy: 0.7917\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.8696\n",
      "Epoch 28: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 250s 4s/step - loss: 0.3013 - accuracy: 0.8696 - val_loss: 0.6761 - val_accuracy: 0.7638\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.8771\n",
      "Epoch 29: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 257s 4s/step - loss: 0.2859 - accuracy: 0.8771 - val_loss: 2.7438 - val_accuracy: 0.5200\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.8889\n",
      "Epoch 30: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 239s 4s/step - loss: 0.2721 - accuracy: 0.8889 - val_loss: 2.0123 - val_accuracy: 0.6938\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8783\n",
      "Epoch 31: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 235s 4s/step - loss: 0.2819 - accuracy: 0.8783 - val_loss: 3.2240 - val_accuracy: 0.4986\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.8880\n",
      "Epoch 32: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 227s 4s/step - loss: 0.2668 - accuracy: 0.8880 - val_loss: 3.4231 - val_accuracy: 0.4844\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.8901\n",
      "Epoch 33: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 222s 4s/step - loss: 0.2631 - accuracy: 0.8901 - val_loss: 1.3703 - val_accuracy: 0.5019\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.8936\n",
      "Epoch 34: val_loss did not improve from 0.58715\n",
      "58/58 [==============================] - 245s 4s/step - loss: 0.2531 - accuracy: 0.8936 - val_loss: 0.8589 - val_accuracy: 0.6003\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9008\n",
      "Epoch 35: val_loss improved from 0.58715 to 0.36955, saving model to Optimized_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 230s 4s/step - loss: 0.2440 - accuracy: 0.9008 - val_loss: 0.3696 - val_accuracy: 0.8710\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.8867\n",
      "Epoch 36: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 236s 4s/step - loss: 0.2786 - accuracy: 0.8867 - val_loss: 2.6123 - val_accuracy: 0.5057\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.8990\n",
      "Epoch 37: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 235s 4s/step - loss: 0.2412 - accuracy: 0.8990 - val_loss: 3.8662 - val_accuracy: 0.4975\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9103\n",
      "Epoch 38: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 241s 4s/step - loss: 0.2227 - accuracy: 0.9103 - val_loss: 4.0721 - val_accuracy: 0.4904\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9165\n",
      "Epoch 39: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 239s 4s/step - loss: 0.2018 - accuracy: 0.9165 - val_loss: 5.0151 - val_accuracy: 0.4872\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9251\n",
      "Epoch 40: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 239s 4s/step - loss: 0.1904 - accuracy: 0.9251 - val_loss: 2.4071 - val_accuracy: 0.5107\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9237\n",
      "Epoch 41: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 242s 4s/step - loss: 0.1901 - accuracy: 0.9237 - val_loss: 4.5147 - val_accuracy: 0.4992\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9241\n",
      "Epoch 42: val_loss did not improve from 0.36955\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.1865 - accuracy: 0.9241 - val_loss: 0.7474 - val_accuracy: 0.8196\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9312\n",
      "Epoch 43: val_loss improved from 0.36955 to 0.29282, saving model to Optimized_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 242s 4s/step - loss: 0.1702 - accuracy: 0.9312 - val_loss: 0.2928 - val_accuracy: 0.8803\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.9363\n",
      "Epoch 44: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 245s 4s/step - loss: 0.1673 - accuracy: 0.9363 - val_loss: 1.0116 - val_accuracy: 0.5998\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9379\n",
      "Epoch 45: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.1582 - accuracy: 0.9379 - val_loss: 4.4369 - val_accuracy: 0.4882\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9408\n",
      "Epoch 46: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 243s 4s/step - loss: 0.1533 - accuracy: 0.9408 - val_loss: 0.3333 - val_accuracy: 0.8901\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9412\n",
      "Epoch 47: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 244s 4s/step - loss: 0.1538 - accuracy: 0.9412 - val_loss: 0.8601 - val_accuracy: 0.7786\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9390\n",
      "Epoch 48: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 244s 4s/step - loss: 0.1560 - accuracy: 0.9390 - val_loss: 7.2341 - val_accuracy: 0.4833\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9337\n",
      "Epoch 49: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 244s 4s/step - loss: 0.1629 - accuracy: 0.9337 - val_loss: 4.1681 - val_accuracy: 0.4948\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9374\n",
      "Epoch 50: val_loss did not improve from 0.29282\n",
      "58/58 [==============================] - 242s 4s/step - loss: 0.1578 - accuracy: 0.9374 - val_loss: 4.8000 - val_accuracy: 0.4833\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "import tensorflow as tf\n",
    "\n",
    "def Optimized_LSTM(input_size):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(layers.Input(input_size))\n",
    "    \n",
    "    model.add(layers.LSTM(units=128, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.LSTM(units=128, return_sequences=False))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_size = (X_train.shape[1],)\n",
    "optimized_lstm = Optimized_LSTM(input_size)\n",
    "\n",
    "optimized_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'Optimized_LSTM_MODEL.h5',\n",
    "        verbose=1,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.001,\n",
    "        patience=20,  \n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "optimized_results = optimized_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128,  \n",
    "    epochs=50,   \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "69b16274-3137-47c0-bcfa-65fd5b3ed8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EÄŸitim PerformansÄ±:\n",
      "Accuracy: 0.5016\n",
      "Loss: 4.6634\n",
      "\n",
      "Test PerformansÄ±:\n",
      "Accuracy: 0.4939\n",
      "Loss: 4.7555\n",
      "72/72 [==============================] - 15s 202ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1157\n",
      "           1       0.49      1.00      0.66      1129\n",
      "\n",
      "    accuracy                           0.49      2286\n",
      "   macro avg       0.25      0.50      0.33      2286\n",
      "weighted avg       0.24      0.49      0.33      2286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Eren\\anaconda3\\envs\\PhishingDetection\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = optimized_lstm.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = optimized_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('\\nEÄŸitim PerformansÄ±:')\n",
    "print(f'Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Loss: {train_loss:.4f}')\n",
    "\n",
    "print('\\nTest PerformansÄ±:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "y_pred = (optimized_lstm.predict(X_test) > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc1d5c-c5e9-44e5-a14a-5d1a448724d5",
   "metadata": {},
   "source": [
    "# LSTM+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2b5e7199-b4be-4505-bcd6-7bbbfd1e4375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9144, 1052, 1) (9144,)\n",
      "(2286, 1052, 1) (2286,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1052, 1)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)\n",
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "input_size = X_train[1].shape\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b20f5f86-cfba-433b-b012-3fee66a0308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 1052, 16)          64        \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 1052, 16)          0         \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 1052, 16)          64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 526, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 526, 32)           1568      \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 526, 32)           0         \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 526, 32)           128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 263, 32)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 263, 64)           6208      \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 263, 64)           0         \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 263, 64)           256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPooli  (None, 132, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 132, 128)          24704     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 132, 128)          0         \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  (None, 132, 128)          512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 66, 128)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 66, 256)           98560     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 66, 256)           0         \n",
      "                                                                 \n",
      " batch_normalization_42 (Ba  (None, 66, 256)           1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 66, 128)           197120    \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 66, 128)           0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8448)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               1081472   \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1428321 (5.45 MB)\n",
      "Trainable params: 1427329 (5.44 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CNN_LSTM(input_size):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(input_size))\n",
    "    model.add(layers.Conv1D(filters = 16,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 128,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2,padding = 'same'))\n",
    "    model.add(layers.Conv1D(filters = 256,kernel_size = 3,activation = 'relu',padding = 'same'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LSTM(128,return_sequences=True))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(128,activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "CNN_LSTM_model = CNN_LSTM(input_size)\n",
    "CNN_LSTM_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c13b474b-ad04-4a1d-8988-da6281ac127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.7003\n",
      "Epoch 1: val_loss improved from inf to 0.71757, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 59s 966ms/step - loss: 0.5447 - accuracy: 0.7003 - val_loss: 0.7176 - val_accuracy: 0.4833\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8029\n",
      "Epoch 2: val_loss did not improve from 0.71757\n",
      "58/58 [==============================] - 55s 952ms/step - loss: 0.4075 - accuracy: 0.8029 - val_loss: 0.7719 - val_accuracy: 0.4833\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8473\n",
      "Epoch 3: val_loss improved from 0.71757 to 0.68324, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 55s 952ms/step - loss: 0.3399 - accuracy: 0.8473 - val_loss: 0.6832 - val_accuracy: 0.4833\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.8640\n",
      "Epoch 4: val_loss improved from 0.68324 to 0.63826, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 55s 957ms/step - loss: 0.3098 - accuracy: 0.8640 - val_loss: 0.6383 - val_accuracy: 0.6769\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.8756\n",
      "Epoch 5: val_loss improved from 0.63826 to 0.61032, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 56s 959ms/step - loss: 0.2841 - accuracy: 0.8756 - val_loss: 0.6103 - val_accuracy: 0.6282\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.8874\n",
      "Epoch 6: val_loss improved from 0.61032 to 0.53558, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 56s 962ms/step - loss: 0.2671 - accuracy: 0.8874 - val_loss: 0.5356 - val_accuracy: 0.7217\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.8893\n",
      "Epoch 7: val_loss improved from 0.53558 to 0.44815, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 56s 959ms/step - loss: 0.2551 - accuracy: 0.8893 - val_loss: 0.4482 - val_accuracy: 0.7999\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.8988\n",
      "Epoch 8: val_loss improved from 0.44815 to 0.33692, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 55s 953ms/step - loss: 0.2375 - accuracy: 0.8988 - val_loss: 0.3369 - val_accuracy: 0.8546\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.8968\n",
      "Epoch 9: val_loss improved from 0.33692 to 0.29022, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 56s 972ms/step - loss: 0.2288 - accuracy: 0.8968 - val_loss: 0.2902 - val_accuracy: 0.8803\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9102\n",
      "Epoch 10: val_loss improved from 0.29022 to 0.27149, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 57s 978ms/step - loss: 0.2136 - accuracy: 0.9102 - val_loss: 0.2715 - val_accuracy: 0.8753\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9085\n",
      "Epoch 11: val_loss improved from 0.27149 to 0.24580, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 57s 981ms/step - loss: 0.2109 - accuracy: 0.9085 - val_loss: 0.2458 - val_accuracy: 0.8978\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9152\n",
      "Epoch 12: val_loss improved from 0.24580 to 0.24275, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 57s 984ms/step - loss: 0.2003 - accuracy: 0.9152 - val_loss: 0.2428 - val_accuracy: 0.8907\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9236\n",
      "Epoch 13: val_loss improved from 0.24275 to 0.23907, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1795 - accuracy: 0.9236 - val_loss: 0.2391 - val_accuracy: 0.8939\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9191\n",
      "Epoch 14: val_loss did not improve from 0.23907\n",
      "58/58 [==============================] - 57s 992ms/step - loss: 0.1830 - accuracy: 0.9191 - val_loss: 0.2480 - val_accuracy: 0.8999\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9226\n",
      "Epoch 15: val_loss improved from 0.23907 to 0.23558, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1792 - accuracy: 0.9226 - val_loss: 0.2356 - val_accuracy: 0.9038\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9247\n",
      "Epoch 16: val_loss improved from 0.23558 to 0.22921, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1715 - accuracy: 0.9247 - val_loss: 0.2292 - val_accuracy: 0.9065\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9329\n",
      "Epoch 17: val_loss did not improve from 0.22921\n",
      "58/58 [==============================] - 57s 990ms/step - loss: 0.1587 - accuracy: 0.9329 - val_loss: 0.2319 - val_accuracy: 0.9065\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9284\n",
      "Epoch 18: val_loss did not improve from 0.22921\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1608 - accuracy: 0.9284 - val_loss: 0.2488 - val_accuracy: 0.8967\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9344\n",
      "Epoch 19: val_loss did not improve from 0.22921\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1587 - accuracy: 0.9344 - val_loss: 0.2356 - val_accuracy: 0.9054\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9333\n",
      "Epoch 20: val_loss improved from 0.22921 to 0.22561, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1580 - accuracy: 0.9333 - val_loss: 0.2256 - val_accuracy: 0.9092\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9386\n",
      "Epoch 21: val_loss did not improve from 0.22561\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1446 - accuracy: 0.9386 - val_loss: 0.2375 - val_accuracy: 0.9142\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9393\n",
      "Epoch 22: val_loss improved from 0.22561 to 0.22460, saving model to CNN_LSTM_MODEL.h5\n",
      "58/58 [==============================] - 61s 1s/step - loss: 0.1418 - accuracy: 0.9393 - val_loss: 0.2246 - val_accuracy: 0.9049\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9378\n",
      "Epoch 23: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1389 - accuracy: 0.9378 - val_loss: 0.2409 - val_accuracy: 0.9016\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9388\n",
      "Epoch 24: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 998ms/step - loss: 0.1368 - accuracy: 0.9388 - val_loss: 0.2549 - val_accuracy: 0.9038\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9401\n",
      "Epoch 25: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 998ms/step - loss: 0.1362 - accuracy: 0.9401 - val_loss: 0.2506 - val_accuracy: 0.9049\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9441\n",
      "Epoch 26: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1309 - accuracy: 0.9441 - val_loss: 0.2965 - val_accuracy: 0.8972\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9423\n",
      "Epoch 27: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1332 - accuracy: 0.9423 - val_loss: 0.2762 - val_accuracy: 0.9071\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9461\n",
      "Epoch 28: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 999ms/step - loss: 0.1223 - accuracy: 0.9461 - val_loss: 0.2992 - val_accuracy: 0.8972\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9475\n",
      "Epoch 29: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1214 - accuracy: 0.9475 - val_loss: 0.2596 - val_accuracy: 0.9065\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9459\n",
      "Epoch 30: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1214 - accuracy: 0.9459 - val_loss: 0.2726 - val_accuracy: 0.9054\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9471\n",
      "Epoch 31: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1184 - accuracy: 0.9471 - val_loss: 0.2775 - val_accuracy: 0.9060\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9490\n",
      "Epoch 32: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1215 - accuracy: 0.9490 - val_loss: 0.2821 - val_accuracy: 0.9016\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9482\n",
      "Epoch 33: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1193 - accuracy: 0.9482 - val_loss: 0.2599 - val_accuracy: 0.9114\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9467\n",
      "Epoch 34: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1215 - accuracy: 0.9467 - val_loss: 0.3312 - val_accuracy: 0.8912\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9506\n",
      "Epoch 35: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1150 - accuracy: 0.9506 - val_loss: 0.3791 - val_accuracy: 0.8917\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9497\n",
      "Epoch 36: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 999ms/step - loss: 0.1156 - accuracy: 0.9497 - val_loss: 0.3637 - val_accuracy: 0.8945\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9483\n",
      "Epoch 37: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1165 - accuracy: 0.9483 - val_loss: 0.3577 - val_accuracy: 0.8934\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9513\n",
      "Epoch 38: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 999ms/step - loss: 0.1112 - accuracy: 0.9513 - val_loss: 0.3451 - val_accuracy: 0.9021\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9486\n",
      "Epoch 39: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1162 - accuracy: 0.9486 - val_loss: 0.2975 - val_accuracy: 0.9060\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9486\n",
      "Epoch 40: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1189 - accuracy: 0.9486 - val_loss: 0.2658 - val_accuracy: 0.9081\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9530\n",
      "Epoch 41: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1076 - accuracy: 0.9530 - val_loss: 0.2578 - val_accuracy: 0.9060\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9537\n",
      "Epoch 42: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1049 - accuracy: 0.9537 - val_loss: 0.2950 - val_accuracy: 0.9103\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9515\n",
      "Epoch 43: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1080 - accuracy: 0.9515 - val_loss: 0.3021 - val_accuracy: 0.9054\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9565\n",
      "Epoch 44: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1000ms/step - loss: 0.0995 - accuracy: 0.9565 - val_loss: 0.2903 - val_accuracy: 0.9054\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9556\n",
      "Epoch 45: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1026 - accuracy: 0.9556 - val_loss: 0.2820 - val_accuracy: 0.9081\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9563\n",
      "Epoch 46: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1048 - accuracy: 0.9563 - val_loss: 0.2891 - val_accuracy: 0.9087\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9554\n",
      "Epoch 47: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.1009 - accuracy: 0.9554 - val_loss: 0.2939 - val_accuracy: 0.9043\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9563\n",
      "Epoch 48: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.0986 - accuracy: 0.9563 - val_loss: 0.2800 - val_accuracy: 0.9109\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9527\n",
      "Epoch 49: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 59s 1s/step - loss: 0.1109 - accuracy: 0.9527 - val_loss: 0.2704 - val_accuracy: 0.9131\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9550\n",
      "Epoch 50: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 997ms/step - loss: 0.1023 - accuracy: 0.9550 - val_loss: 0.2762 - val_accuracy: 0.9131\n",
      "Epoch 51/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9538\n",
      "Epoch 51: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 996ms/step - loss: 0.1000 - accuracy: 0.9538 - val_loss: 0.2871 - val_accuracy: 0.9103\n",
      "Epoch 52/200\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9565\n",
      "Epoch 52: val_loss did not improve from 0.22460\n",
      "58/58 [==============================] - 58s 1s/step - loss: 0.0969 - accuracy: 0.9565 - val_loss: 0.2964 - val_accuracy: 0.9054\n",
      "Epoch 52: early stopping\n"
     ]
    }
   ],
   "source": [
    "CNN_LSTM_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint('CNN_LSTM_MODEL.h5',verbose=1,save_best_only=True),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001,patience=30,verbose=1)]\n",
    "CNN_LSTM_results = CNN_LSTM_model.fit(X_train,y_train,validation_split=0.2,batch_size=128,epochs=200,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878cb2a-c0b1-4061-bd58-363305593a35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15e1ae-0530-4da6-a921-a9409ad5511e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
